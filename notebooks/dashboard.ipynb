{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape (342, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>player_1_model</th>\n",
       "      <th>player_1_temperature</th>\n",
       "      <th>player_2_model</th>\n",
       "      <th>player_2_temperature</th>\n",
       "      <th>player_1_won20240324081115</th>\n",
       "      <th>openai:gpt-3.5-turbo-0125</th>\n",
       "      <th>0.0</th>\n",
       "      <th>openai:gpt-3.5-turbo-0125.1</th>\n",
       "      <th>0.0.1</th>\n",
       "      <th>False</th>\n",
       "      <th>player_1_won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20240324081116</td>\n",
       "      <td>mistral:mistral-small-latest</td>\n",
       "      <td>0.0</td>\n",
       "      <td>openai:gpt-3.5-turbo-0125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20240324081132</td>\n",
       "      <td>mistral:mistral-small-latest</td>\n",
       "      <td>0.0</td>\n",
       "      <td>openai:gpt-4-0125-preview</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20240324081140</td>\n",
       "      <td>mistral:mistral-large-latest</td>\n",
       "      <td>0.0</td>\n",
       "      <td>openai:gpt-3.5-turbo-0125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20240324081140</td>\n",
       "      <td>openai:gpt-4-0125-preview</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mistral:mistral-small-latest</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20240324081154</td>\n",
       "      <td>mistral:mistral-medium-latest</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mistral:mistral-medium-latest</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                  player_1_model   player_1_temperature  \\\n",
       "0  20240324081116    mistral:mistral-small-latest                    0.0   \n",
       "1  20240324081132    mistral:mistral-small-latest                    0.0   \n",
       "2  20240324081140    mistral:mistral-large-latest                    0.0   \n",
       "3  20240324081140       openai:gpt-4-0125-preview                    0.0   \n",
       "4  20240324081154   mistral:mistral-medium-latest                    0.0   \n",
       "\n",
       "                   player_2_model   player_2_temperature  \\\n",
       "0       openai:gpt-3.5-turbo-0125                    0.0   \n",
       "1       openai:gpt-4-0125-preview                    0.0   \n",
       "2       openai:gpt-3.5-turbo-0125                    0.0   \n",
       "3    mistral:mistral-small-latest                    0.0   \n",
       "4   mistral:mistral-medium-latest                    0.0   \n",
       "\n",
       "   player_1_won20240324081115   openai:gpt-3.5-turbo-0125   0.0  \\\n",
       "0                        True                         NaN   NaN   \n",
       "1                        True                         NaN   NaN   \n",
       "2                       False                         NaN   NaN   \n",
       "3                       False                         NaN   NaN   \n",
       "4                       False                         NaN   NaN   \n",
       "\n",
       "    openai:gpt-3.5-turbo-0125.1   0.0.1   False  player_1_won  \n",
       "0                           NaN     NaN     NaN           NaN  \n",
       "1                           NaN     NaN     NaN           NaN  \n",
       "2                           NaN     NaN     NaN           NaN  \n",
       "3                           NaN     NaN     NaN           NaN  \n",
       "4                           NaN     NaN     NaN           NaN  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV files\n",
    "df_stan = pd.read_csv('../results/results_stan.csv')\n",
    "df_nico = pd.read_csv('../results/results_nico.csv')\n",
    "\n",
    "# Merge the dataframes in a df DataFrame\n",
    "df = pd.concat([df_stan, df_nico])\n",
    "\n",
    "print(f\"df shape: {df.shape}\")\n",
    "\n",
    "# Print the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['True' 'False']\n",
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "# Check the different values for temperature\n",
    "print(df['player_1_won'].unique())\n",
    "print(df['player_2_temperature'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'player_1_model', 'player_1_temperature', 'player_2_model',\n",
      "       'player_2_temperature', 'player_1_won20240324081115',\n",
      "       'openai:gpt-3.5-turbo-0125', '0.0', 'openai:gpt-3.5-turbo-0125.1',\n",
      "       '0.0.1', 'False'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Strip leading and trailing spaces from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Do the same on the text values\n",
    "df = df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "\n",
    "# Show the datframe keys\n",
    "print(df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of wins for each model:\n",
      "{'mistral:mistral-small-latest': 16, 'mistral:mistral-large-latest': 15, 'openai:gpt-4-0125-preview': 17, 'mistral:mistral-medium-latest': 25, 'openai:gpt-4': 22, 'openai:gpt-3.5-turbo-0125': 16}\n"
     ]
    }
   ],
   "source": [
    "# Get the number of wins for each model\n",
    "player_nb_wins = {player_id: 0 for player_id in pd.concat([df['player_1_model'], df['player_1_model']]).unique()}\n",
    "\n",
    "# Go over the rows of the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    if row[\"player_1_won20240324081115\"]:\n",
    "        player_nb_wins[row[\"player_1_model\"]] += 1\n",
    "    else:\n",
    "        player_nb_wins[row[\"player_2_model\"]] += 1\n",
    "\n",
    "print(\"Number of wins for each model:\")\n",
    "print(player_nb_wins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'player_1_model', 'player_1_temperature', 'player_2_model',\n",
      "       'player_2_temperature', 'player_1_won', 'openai:gpt-3.5-turbo-0125',\n",
      "       '0.0', 'openai:gpt-3.5-turbo-0125.1', '0.0.1', 'False'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Strip leading and trailing spaces from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Do the same on the text values\n",
    "df = df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "\n",
    "# Rename the column player_1_won20240324081115\n",
    "df.rename(columns={\"player_1_won20240324081115\": \"player_1_won\"}, inplace=True)\n",
    "\n",
    "df.head()\n",
    "\n",
    "# Show the datframe keys\n",
    "print(df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Players: ['mistral:mistral-small-latest' 'mistral:mistral-large-latest'\n",
      " 'openai:gpt-4-0125-preview' 'mistral:mistral-medium-latest'\n",
      " 'openai:gpt-4' 'openai:gpt-3.5-turbo-0125']\n"
     ]
    }
   ],
   "source": [
    "# Get the different contending models\n",
    "players = df['player_1_model'].unique()\n",
    "print(f\"Players: {players}\")\n",
    "\n",
    "# Compute the ELO \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player_1_won values:\n",
      "player_1_won\n",
      "False    57\n",
      "True     54\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display the values of the player_1_won\n",
    "print(\"player_1_won values:\")\n",
    "print(df['player_1_won'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the relative scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of wins for each model:\n",
      "{'mistral:mistral-small-latest': 18, 'mistral:mistral-large-latest': 5, 'openai:gpt-4-0125-preview': 20, 'mistral:mistral-medium-latest': 8, 'openai:gpt-4': 27, 'openai:gpt-3.5-turbo-0125': 33}\n"
     ]
    }
   ],
   "source": [
    "# Get the win rate of each model\n",
    "\n",
    "# Get a list of each model name in player_1_model and player_2_model\n",
    "model_names = pd.concat([df['player_1_model'], df['player_2_model']]).unique()\n",
    "\n",
    "# Go over the rows of the DataFrame\n",
    "model_wins = {model_name: 0 for model_name in model_names}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row[\"player_1_won\"] == \"True\":\n",
    "        model_wins[row[\"player_1_model\"]] += 1\n",
    "    else:\n",
    "        model_wins[row[\"player_2_model\"]] += 1\n",
    "\n",
    "print(\"Number of wins for each model:\")\n",
    "print(model_wins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fights for each model:\n",
      "{'mistral:mistral-small-latest': 29, 'mistral:mistral-large-latest': 27, 'openai:gpt-4-0125-preview': 44, 'mistral:mistral-medium-latest': 40, 'openai:gpt-4': 45, 'openai:gpt-3.5-turbo-0125': 37}\n"
     ]
    }
   ],
   "source": [
    "# Get the number of fight for each model\n",
    "model_fights = {model_name: 0 for model_name in model_names}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    model_fights[row[\"player_1_model\"]] += 1\n",
    "    model_fights[row[\"player_2_model\"]] += 1\n",
    "\n",
    "print(\"Number of fights for each model:\")\n",
    "print(model_fights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win rate for each model:\n",
      "mistral:mistral-small-latest: 0.6206896551724138\n",
      "mistral:mistral-large-latest: 0.18518518518518517\n",
      "openai:gpt-4-0125-preview: 0.45454545454545453\n",
      "mistral:mistral-medium-latest: 0.2\n",
      "openai:gpt-4: 0.6\n",
      "openai:gpt-3.5-turbo-0125: 0.8918918918918919\n"
     ]
    }
   ],
   "source": [
    "# Get the win rate of each model\n",
    "model_win_rate = {model_name: model_wins[model_name] / model_fights[model_name] for model_name in model_names}\n",
    "\n",
    "print(\"Win rate for each model:\")\n",
    "for key, value in model_win_rate.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the ELO rating for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mistral:mistral-small-latest': 1551.2345821962522, 'mistral:mistral-large-latest': 1344.3907597769983, 'openai:gpt-4-0125-preview': 1500.5052108897266, 'mistral:mistral-medium-latest': 1282.174990619322, 'openai:gpt-4': 1565.1031248329953, 'openai:gpt-3.5-turbo-0125': 1756.5913316847057}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>openai:gpt-3.5-turbo-0125</td>\n",
       "      <td>1756.591332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>openai:gpt-4</td>\n",
       "      <td>1565.103125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mistral:mistral-small-latest</td>\n",
       "      <td>1551.234582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>openai:gpt-4-0125-preview</td>\n",
       "      <td>1500.505211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mistral:mistral-large-latest</td>\n",
       "      <td>1344.390760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model       Rating\n",
       "5     openai:gpt-3.5-turbo-0125  1756.591332\n",
       "4                  openai:gpt-4  1565.103125\n",
       "0  mistral:mistral-small-latest  1551.234582\n",
       "2     openai:gpt-4-0125-preview  1500.505211\n",
       "1  mistral:mistral-large-latest  1344.390760"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize player ratings\n",
    "player_ratings = {player_id: 1500 for player_id in model_names}\n",
    "\n",
    "def elo_expected_score(rating_a, rating_b):\n",
    "    return 1 / (1 + 10**((rating_b - rating_a) / 400))\n",
    "\n",
    "def elo_update(winner_rating, loser_rating, k=32):\n",
    "    expected_score_winner = elo_expected_score(winner_rating, loser_rating)\n",
    "    expected_score_loser = 1 - expected_score_winner\n",
    "    new_winner_rating = winner_rating + k * (1 - expected_score_winner)\n",
    "    new_loser_rating = loser_rating + k * (0 - expected_score_loser)\n",
    "    return new_winner_rating, new_loser_rating\n",
    "\n",
    "# Iterate through matches to update ELO ratings\n",
    "for index, row in df.iterrows():\n",
    "    player1, player2, player1_won = row['player_1_model'], row['player_2_model'], row['player_1_won']\n",
    "\n",
    "    # If it's a match against itself, skip\n",
    "    if player1 == player2:\n",
    "        continue\n",
    "    \n",
    "    if player1_won == \"True\":\n",
    "        winner, loser = player1, player2\n",
    "    else:\n",
    "        winner, loser = player2, player1\n",
    "    \n",
    "    new_winner_rating, new_loser_rating = elo_update(player_ratings[winner], player_ratings[loser])\n",
    "    \n",
    "    player_ratings[winner] = new_winner_rating\n",
    "    player_ratings[loser] = new_loser_rating\n",
    "\n",
    "# Print updated ratings\n",
    "print(player_ratings)\n",
    "\n",
    "# Make it a DataFrame so we can have a nice display\n",
    "ratings_df = pd.DataFrame(player_ratings.items(), columns=['Model', 'Rating'])\n",
    "\n",
    "# Sort the DataFrame by rating\n",
    "ratings_df = ratings_df.sort_values(by='Rating', ascending=False)\n",
    "\n",
    "# Display the ratings\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-colosseum-2LG-TNbW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
